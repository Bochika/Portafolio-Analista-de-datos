{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "b89b2c51-84b0-4b8f-a75c-9100db584084",
      "cell_type": "markdown",
      "source": "# Utilizaci√≥n de pandas  en el an√°lisis de datos",
      "metadata": {}
    },
    {
      "id": "1f442195-b9dd-49f5-b43d-3948fa97ca23",
      "cell_type": "markdown",
      "source": "## poder subir un archivo, en este caso .cvs ubicado en un archivo local, Le hacemos una primera mirada de los primeros y los √∫ltimos datos para ver como est√° compuesta, vemos informaci√≥n importante y si hay duplicados.\n",
      "metadata": {}
    },
    {
      "id": "5fb1c683-161e-499a-a2b0-8f0c2c5d4099",
      "cell_type": "code",
      "source": "import pandas as pd\nfrom collections import defaultdict\n\n\nnombre_archivo = \"Coffe_sales.csv\" \n\ntry:\n    df = pd.read_csv(nombre_archivo)\n    \n    print(\"¬°Archivo cargado exitosamente en JupyterLite!\")\n    print(\"\\nPrimeras 5 filas del DataFrame:\")\n    print(df.head())\n    print(df.info())\n    df.describe()\n    print(df.duplicated().sum())\n    \n\nexcept Exception as e:\n    print(f\"Ocurri√≥ un error al leer el archivo: {e}\")\n\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "¬°Archivo cargado exitosamente en JupyterLite!\n\nPrimeras 5 filas del DataFrame:\n   hour_of_day cash_type  money    coffee_name Time_of_Day Weekday Month_name  \\\n0           10      card   38.7          Latte     Morning     Fri        Mar   \n1           12      card   38.7  Hot Chocolate   Afternoon     Fri        Mar   \n2           12      card   38.7  Hot Chocolate   Afternoon     Fri        Mar   \n3           13      card   28.9      Americano   Afternoon     Fri        Mar   \n4           13      card   38.7          Latte   Afternoon     Fri        Mar   \n\n   Weekdaysort  Monthsort        Date             Time  \n0            5          3  2024-03-01  10:15:50.520000  \n1            5          3  2024-03-01  12:19:22.539000  \n2            5          3  2024-03-01  12:20:18.089000  \n3            5          3  2024-03-01  13:46:33.006000  \n4            5          3  2024-03-01  13:48:14.626000  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3547 entries, 0 to 3546\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   hour_of_day  3547 non-null   int64  \n 1   cash_type    3547 non-null   object \n 2   money        3547 non-null   float64\n 3   coffee_name  3547 non-null   object \n 4   Time_of_Day  3547 non-null   object \n 5   Weekday      3547 non-null   object \n 6   Month_name   3547 non-null   object \n 7   Weekdaysort  3547 non-null   int64  \n 8   Monthsort    3547 non-null   int64  \n 9   Date         3547 non-null   object \n 10  Time         3547 non-null   object \ndtypes: float64(1), int64(3), object(7)\nmemory usage: 207.9+ KB\nNone\n0\n"
        }
      ],
      "execution_count": 23
    },
    {
      "id": "44d9276a-f602-44bf-95cf-68aff83efab3",
      "cell_type": "markdown",
      "source": "# Se le hizo un an√°lisis al conjunto, no tiene datos faltantes o extra√±os, tenemos problemas con el formato de los tiempos",
      "metadata": {}
    },
    {
      "id": "91deff07-df92-4d04-82a6-e6dc9dd4068f",
      "cell_type": "code",
      "source": "\ndf['Full_Timestamp_Str'] = df['Date'].astype(str) + ' ' + df['Time'].astype(str)\n\n# Para cuantificar errores\ndf['Transaction_DateTime'] = pd.to_datetime(df['Full_Timestamp_Str'], \n                                             errors='coerce', \n                                             format='mixed')\n\n# Validar la limpieza y eliminar la columna temporal\nnan_count = df['Transaction_DateTime'].isna().sum()\nprint(\"\\n--- ¬°ERROR DE TIEMPO CORREGIDO Y VALIDADO! ---\")\nprint(f\"Total de valores que fallaron en la conversi√≥n (NaT): {nan_count}\")\n\n# Limpieza del DataFrame\ndf = df.drop(columns=['Full_Timestamp_Str'])\n\n# Validar la nueva estructura del DataFrame\nprint(\"\\nValidaci√≥n de las primeras 5 filas con el nuevo campo de tiempo:\")\nprint(df[['Date', 'Time', 'Transaction_DateTime']].head())\ndf.info()\n\n# Iterar sobre las columnas de tipo 'object' (categ√≥ricas) para ver los valores √∫nicos\nprint(\"\\n--- Inspecci√≥n de Valores √önicos en Columnas Categ√≥ricas ---\")\nfor col in df.select_dtypes(include=['object']).columns:\n    print(f\"\\nColumna: {col}\")\n    \n    # Muestra los valores √∫nicos y su frecuencia de aparici√≥n\n    print(df[col].value_counts())\n    \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- ¬°ERROR DE TIEMPO CORREGIDO Y VALIDADO! ---\nTotal de valores que fallaron en la conversi√≥n (NaT): 0\n\nValidaci√≥n de las primeras 5 filas con el nuevo campo de tiempo:\n         Date             Time    Transaction_DateTime\n0  2024-03-01  10:15:50.520000 2024-03-01 10:15:50.520\n1  2024-03-01  12:19:22.539000 2024-03-01 12:19:22.539\n2  2024-03-01  12:20:18.089000 2024-03-01 12:20:18.089\n3  2024-03-01  13:46:33.006000 2024-03-01 13:46:33.006\n4  2024-03-01  13:48:14.626000 2024-03-01 13:48:14.626\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3547 entries, 0 to 3546\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype         \n---  ------                --------------  -----         \n 0   hour_of_day           3547 non-null   int64         \n 1   cash_type             3547 non-null   object        \n 2   money                 3547 non-null   float64       \n 3   coffee_name           3547 non-null   object        \n 4   Time_of_Day           3547 non-null   object        \n 5   Weekday               3547 non-null   object        \n 6   Month_name            3547 non-null   object        \n 7   Weekdaysort           3547 non-null   int64         \n 8   Monthsort             3547 non-null   int64         \n 9   Date                  3547 non-null   object        \n 10  Time                  3547 non-null   object        \n 11  Transaction_DateTime  3547 non-null   datetime64[ns]\ndtypes: datetime64[ns](1), float64(1), int64(3), object(7)\nmemory usage: 235.6+ KB\n\n--- Inspecci√≥n de Valores √önicos en Columnas Categ√≥ricas ---\n\nColumna: cash_type\ncash_type\ncard    3547\nName: count, dtype: int64\n\nColumna: coffee_name\ncoffee_name\nAmericano with Milk    809\nLatte                  757\nAmericano              564\nCappuccino             486\nCortado                287\nHot Chocolate          276\nCocoa                  239\nEspresso               129\nName: count, dtype: int64\n\nColumna: Time_of_Day\nTime_of_Day\nAfternoon    1205\nMorning      1181\nNight        1161\nName: count, dtype: int64\n\nColumna: Weekday\nWeekday\nTue    572\nMon    544\nFri    532\nThu    510\nWed    500\nSat    470\nSun    419\nName: count, dtype: int64\n\nColumna: Month_name\nMonth_name\nMar    494\nOct    426\nFeb    423\nSep    344\nAug    272\nNov    259\nDec    259\nMay    241\nJul    237\nJun    223\nJan    201\nApr    168\nName: count, dtype: int64\n\nColumna: Date\nDate\n2024-10-11    26\n2025-02-03    25\n2024-09-22    24\n2024-07-30    24\n2025-02-05    24\n              ..\n2024-08-29     1\n2024-07-17     1\n2024-03-24     1\n2024-03-17     1\n2024-04-27     1\nName: count, Length: 381, dtype: int64\n\nColumna: Time\nTime\n10:15:50.520000    1\n09:23:30.556000    1\n18:38:28.685000    1\n07:50:36.572000    1\n07:51:59.373000    1\n                  ..\n15:21:27.260000    1\n17:24:22.788000    1\n18:10:03.723000    1\n18:59:18.279000    1\n18:11:38.635000    1\nName: count, Length: 3547, dtype: int64\n"
        }
      ],
      "execution_count": 24
    },
    {
      "id": "8dc361f6-a1b6-455d-b18d-143a7581226c",
      "cell_type": "markdown",
      "source": "# Ya los datos est√°n totalmente limpios y completos",
      "metadata": {}
    },
    {
      "id": "6b716d3f-2547-4756-bb9c-9f3deb7295aa",
      "cell_type": "markdown",
      "source": "# Ahora vamos a extraer informaci√≥n valiosa con ayuda de pandas",
      "metadata": {}
    },
    {
      "id": "0b6869c6-b4c5-4c8f-ad62-a710f111ec63",
      "cell_type": "code",
      "source": "\ndias_ordenados = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n\ndemanda_cruzada = pd.crosstab(\n    df['Weekday'], \n    df['Time_of_Day']\n).reindex(dias_ordenados)\n\nprint(\"\\n--- Demanda Semanal por Momento del D√≠a (Conteo de Ventas) ---\")\nprint(demanda_cruzada)\n\n# Agrupamos por Momento del D√≠a y por Nombre del Caf√©, y contamos las ventas\nventas_por_momento_y_cafe = df.groupby(['Time_of_Day', 'coffee_name']).size()\n\n# Usamos 'idxmax' en el nivel interior (coffee_name) para encontrar el √≠ndice (nombre del caf√©)\n# que tuvo la mayor venta en cada Time_of_Day.\ncafe_lider_por_momento = ventas_por_momento_y_cafe.groupby(level=0).idxmax()\n\nprint(\"\\n--- Caf√© L√≠der de Ventas en Cada Momento del D√≠a ---\")\nprint(cafe_lider_por_momento)\n\n# Inicializar y generar el diccionario (Repetimos la l√≥gica del paso anterior para asegurar la ejecuci√≥n)\nreportes_por_cafe = defaultdict(pd.DataFrame)\n\nfor cafe in df['coffee_name'].unique():\n    # Filtrar el DataFrame original\n    df_filtrado = df[df['coffee_name'] == cafe]\n    \n    # Crear la Tabla Din√°mica (Pivot Table)\n    pivot_cafe = df_filtrado.pivot_table(\n        index='Time_of_Day', \n        columns='Weekday', \n        values='hour_of_day', \n        aggfunc='count'\n    )\n    \n    # Reordenar las columnas y rellenar los posibles valores NaN (cero ventas) con 0\n    pivot_cafe = pivot_cafe.reindex(columns=dias_ordenados, fill_value=0)\n    \n    reportes_por_cafe[cafe] = pivot_cafe\n\n\n# 1. Bucle de Impresi√≥n de Todos los Reportes (La Solicitud Clave)\nprint(\"\\n\" + \"=\"*50)\nprint(\"     REPORTE COMPLETO DE VENTAS POR PRODUCTO Y DEMANDA\")\nprint(\"=\"*50)\n\n# Iterar sobre el diccionario e imprimir cada DataFrame de la Tabla Din√°mica\nfor nombre_cafe, reporte_df in reportes_por_cafe.items():\n    print(f\"\\n--- ‚òï REPORTE: {nombre_cafe} ---\")\n    print(reporte_df)\n    print(\"-\" * 50)\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Demanda Semanal por Momento del D√≠a (Conteo de Ventas) ---\nTime_of_Day  Afternoon  Morning  Night\nWeekday                               \nMon                177      193    174\nTue                160      207    205\nWed                165      165    170\nThu                169      146    195\nFri                172      193    167\nSat                194      157    119\nSun                168      120    131\n\n--- Caf√© L√≠der de Ventas en Cada Momento del D√≠a ---\nTime_of_Day\nAfternoon                (Afternoon, Latte)\nMorning      (Morning, Americano with Milk)\nNight                        (Night, Latte)\ndtype: object\n\n==================================================\n     REPORTE COMPLETO DE VENTAS POR PRODUCTO Y DEMANDA\n==================================================\n\n--- ‚òï REPORTE: Latte ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon     48   33   37   35   38   45   34\nMorning       39   40   33   26   32   22   23\nNight         51   46   38   47   37   28   25\n--------------------------------------------------\n\n--- ‚òï REPORTE: Hot Chocolate ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon      7   11   12    9   14   15   12\nMorning       11    7    8    8    7    5    3\nNight         17   31   15   31   24    4   25\n--------------------------------------------------\n\n--- ‚òï REPORTE: Americano ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon     37   31   43   33   39   28   22\nMorning       37   36   35   31   41   24   15\nNight         19   14   10   18   25   17    9\n--------------------------------------------------\n\n--- ‚òï REPORTE: Americano with Milk ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon     32   33   31   25   27   51   40\nMorning       53   65   49   48   46   42   28\nNight         43   45   33   30   30   27   31\n--------------------------------------------------\n\n--- ‚òï REPORTE: Cocoa ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon     13   13    5    7   17    8   12\nMorning        7   16    4    2   19    5    5\nNight         14   28   17   14   16   10    7\n--------------------------------------------------\n\n--- ‚òï REPORTE: Cortado ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon      9   17    5   19    9   11   18\nMorning       22   20   14   11   22   38   16\nNight          4    7   12   12    6    7    8\n--------------------------------------------------\n\n--- ‚òï REPORTE: Espresso ---\nWeekday      Mon  Tue   Wed   Thu  Fri  Sat  Sun\nTime_of_Day                                     \nAfternoon    5.0  6.0  11.0  14.0  5.0  7.0  8.0\nMorning      3.0  6.0   6.0   8.0  9.0  7.0  5.0\nNight        2.0  4.0   8.0   5.0  7.0  NaN  3.0\n--------------------------------------------------\n\n--- ‚òï REPORTE: Cappuccino ---\nWeekday      Mon  Tue  Wed  Thu  Fri  Sat  Sun\nTime_of_Day                                   \nAfternoon     26   16   21   27   23   29   22\nMorning       21   17   16   12   17   14   25\nNight         24   30   37   38   22   26   23\n--------------------------------------------------\n"
        }
      ],
      "execution_count": 25
    },
    {
      "id": "c88d5751-e593-4f3e-be10-9120c66a2b7c",
      "cell_type": "markdown",
      "source": "# Para sacar m√©tricas seguras y poder ser certeros con los datos, debemos ver que los datos por d√≠as sean equitativos. Puede que hayan m√°s lunes que jueves, llevando a lunes a tener una mayor percepci√≥n, que podr√≠a ser falsa.",
      "metadata": {}
    },
    {
      "id": "e77a5069-ca7e-4705-bb2c-5e311d21f667",
      "cell_type": "code",
      "source": "# 1. Ventas Totales por D√≠a: Contar el n√∫mero de transacciones por cada d√≠a de la semana\nventas_totales_por_dia = df.groupby('Weekday').size().reindex(dias_ordenados, fill_value=0)\n\n# 2. Conteo de Ocurrencias del D√≠a (El paso clave para la normalizaci√≥n):\n# Eliminamos las filas duplicadas por 'Date' y luego contamos cu√°ntas veces aparece cada 'Weekday'.\n# Esto nos dice cu√°ntos Lunes, Martes, etc., hubo en el per√≠odo total.\nconteo_dias_unicos = df.drop_duplicates(subset=['Date'])['Weekday'].value_counts().reindex(dias_ordenados, fill_value=0)\n\n# 3. Calcular la Tasa Promedio de Ventas por D√≠a (M√©trica Segura)\n# Tasa Promedio = Ventas Totales / Conteo de D√≠as √önicos\ntasa_promedio_ventas = (ventas_totales_por_dia / conteo_dias_unicos).round(2).sort_values(ascending=False)\n\nprint(\"\\n--- üìà TASA PROMEDIO DE VENTAS DIARIAS NORMALIZADA ---\")\nprint(\"Este es el verdadero indicador de demanda, libre de sesgo.\")\nprint(\"-\" * 50)\nprint(tasa_promedio_ventas)\nprint(\"-\" * 50)\n\n# Opcional: Mostrar el conteo de d√≠as √∫nicos para verificar la normalizaci√≥n\nprint(\"\\nConteo de D√≠as √önicos en el Per√≠odo Analizado (Para Verificaci√≥n):\")\nprint(conteo_dias_unicos)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- üìà TASA PROMEDIO DE VENTAS DIARIAS NORMALIZADA ---\nEste es el verdadero indicador de demanda, libre de sesgo.\n--------------------------------------------------\nWeekday\nTue    10.40\nMon     9.89\nWed     9.62\nFri     9.50\nThu     9.44\nSat     8.55\nSun     7.76\ndtype: float64\n--------------------------------------------------\n\nConteo de D√≠as √önicos en el Per√≠odo Analizado (Para Verificaci√≥n):\nWeekday\nMon    55\nTue    55\nWed    52\nThu    54\nFri    56\nSat    55\nSun    54\nName: count, dtype: int64\n"
        }
      ],
      "execution_count": 26
    },
    {
      "id": "4ae96176-dc15-4030-b3a6-88ba9be8c294",
      "cell_type": "markdown",
      "source": "## Vamos a establecer c√∫al fue el rango",
      "metadata": {}
    },
    {
      "id": "aa5f13cb-3f3f-4c01-9b27-f9c3fa7fd368",
      "cell_type": "code",
      "source": "df['Date'] = pd.to_datetime(df['Date'])\n\n# Calculamos la fecha m√°s antigua y la m√°s reciente\nfecha_inicio = df['Date'].min().strftime('%Y-%m-%d')\nfecha_fin = df['Date'].max().strftime('%Y-%m-%d')\n\nprint(f\"**üóìÔ∏è Rango de Fechas del Dataset:**\")\nprint(f\"Fecha de Inicio: **{fecha_inicio}**\")\nprint(f\"Fecha de Fin: **{fecha_fin}**\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "**üóìÔ∏è Rango de Fechas del Dataset:**\nFecha de Inicio: **2024-03-01**\nFecha de Fin: **2025-03-23**\n"
        }
      ],
      "execution_count": 29
    },
    {
      "id": "a2e42f0e-f929-4530-9f66-f8c824edfe65",
      "cell_type": "code",
      "source": "\n\ndf['Date'] = pd.to_datetime(df['Date'])\nfechas_presentes = df['Date'].dt.date.unique() \n\n# Definir el rango completo esperado\nfecha_inicio = fechas_presentes.min()\nfecha_fin = fechas_presentes.max()\nrango_completo = pd.date_range(start=fecha_inicio, end=fecha_fin, freq='D')\nfechas_esperadas = rango_completo.date\n\n# Identificar las fechas faltantes\nfechas_presentes_set = set(fechas_presentes)\nfechas_faltantes = [fecha for fecha in fechas_esperadas if fecha not in fechas_presentes_set]\n\nprint(f\"**‚è≥ Verificaci√≥n de la Continuidad Temporal:**\\n\")\n\nif fechas_faltantes:\n    print(f\"**¬°ATENCI√ìN! Se encontraron {len(fechas_faltantes)} d√≠as faltantes (saltos) en las ventas.**\")\n    print(f\"\\nPrimeros 10 d√≠as sin datos:\")\n    # Muestra solo la fecha en formato YYYY-MM-DD\n    for fecha in fechas_faltantes[:10]:\n        print(f\"  - {fecha.strftime('%Y-%m-%d')}\")\nelse:\n    print(\"**‚úÖ ¬°Continuidad perfecta! No se encontraron d√≠as sin ventas entre la fecha de inicio y la fecha de fin.**\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "**‚è≥ Verificaci√≥n de la Continuidad Temporal:**\n\n**¬°ATENCI√ìN! Se encontraron 7 d√≠as faltantes (saltos) en las ventas.**\n\nPrimeros 10 d√≠as sin datos:\n  - 2024-05-01\n  - 2024-05-04\n  - 2024-05-05\n  - 2024-11-27\n  - 2025-01-01\n  - 2025-01-19\n  - 2025-01-23\n"
        }
      ],
      "execution_count": 30
    },
    {
      "id": "a5ebdda3-2cc8-4ad3-9ac3-21d2c00cec7a",
      "cell_type": "markdown",
      "source": "## Aqu√≠ podemos ver los d√≠as que no se atendieron, no hay informaci√≥n que nos diga el por qu√© no se atendi√≥ o si fue que ese d√≠a no se vendi√≥",
      "metadata": {}
    },
    {
      "id": "61910350-2a93-4e28-93ab-c9ce927c0ea4",
      "cell_type": "markdown",
      "source": "## Ahora vamos a ver el horario de atenci√≥n",
      "metadata": {}
    },
    {
      "id": "579d862a-8274-4c06-b1d6-25bd9ed3f553",
      "cell_type": "code",
      "source": "# Agrupamos por d√≠a de la semana y encontramos la hora m√≠nima (apertura) y m√°xima (cierre)\nhorarios_atencion = df.groupby('Weekday')['hour_of_day'].agg(\n    Apertura=('min'),\n    Cierre=('max')\n).reset_index()\n\n\n# Mostramos el resultado\nprint(\"\\n**‚è∞ Horarios de Apertura y Cierre por D√≠a:**\")\nprint(horarios_atencion)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n**‚è∞ Horarios de Apertura y Cierre por D√≠a:**\n  Weekday  Apertura  Cierre\n0     Fri         6      22\n1     Mon         6      22\n2     Sat         7      22\n3     Sun         7      22\n4     Thu         7      22\n5     Tue         7      22\n6     Wed         7      22\n"
        }
      ],
      "execution_count": 31
    }
  ]
}